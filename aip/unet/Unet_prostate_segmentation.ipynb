{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josemanuel097/Unet_AIP/blob/master/Unet_prostate_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7QwmzkOZA22",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGjG8T8FXE_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "5cd39b5a-96d1-48e4-aa73-bdf45f2dfe25"
      },
      "source": [
        "\"\"\"\n",
        "Created on Tue Nov 19 12:21:21 2019\n",
        "\n",
        "Advanced Image Processing Exercises 2019\n",
        "Week 3: Machine learning and Pattern Recognition\n",
        "Exercise from Lecture 4: Unet for image segmentation\n",
        "@author: Jose Castillo\n",
        "In this exercise, you will learn:   \n",
        "   *) \n",
        "   *) How to write code to build a unet using the deep learning package Keras.\n",
        "   *) How to present data to your network and train it.\n",
        "   *) Hot the learning of the networks occurs and how to quantify it.\n",
        "   \n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "For this exercise we will use part of a public data set named PROSTATEX, \n",
        "this data set was used in a challange to classify prostate cancer tumor accord_\n",
        "ing different gleasons grade. However, for our learning goals , we will use it\n",
        "to train a network that will learn how to do automatic prostate segmentation.\n",
        "\n",
        "If you want to know more details about this data set you can consult the \n",
        "following link \n",
        "\n",
        "https://wiki.cancerimagingarchive.net/display/Public/SPIE-AAPM-NCI+PROSTATEx+Challenges\n",
        "\n",
        "Description: \n",
        "The PROSTATEx Challenge (\"SPIE-AAPM-NCI Prostate MR Classification Challenge”) \n",
        "focused on quantitative image analysis methods for the diagnostic classification \n",
        "of clinically significant prostate cancers and was held in conjunction with the \n",
        "2017 SPIE Medical Imaging Symposium (see http://www.spie.org/PROSTATEx/).  PROSTATEx \n",
        "ran from November 21, 2016 to January 15, 2017, though a \"live\" version has also \n",
        "been established at https://prostatex.grand-challenge.org which serves as an ongoing\n",
        " way for researchers to benchmark their performance for this task.   \n",
        "\n",
        "\"\"\"\n",
        "!pip install SimpleITK\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SimpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5MB 91kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-1.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05fndfC1Xqyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "import SimpleITK as sitk\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jQ66Bm_aSQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "e6a45422-a2b6-4c23-b6f4-51ee8427b02b"
      },
      "source": [
        "\n",
        "\"\"\"Excercise  Getting to know the data:\n",
        "   Let's get a feeling of the data first. If you check the patient's folder\n",
        "   you will find two folders; images and their corresponding segmentations.\n",
        "   Each image correspond to a 2D prostate axial slice. Use the SimpleITK \n",
        "   package to load a prostate slice from any \n",
        "   patient and the segmentation belonging to that slice, preferebly choose\n",
        "   for one of the slices of the middle section,for instance: if the \n",
        "   prostate has 14 slices, load slice 7 or one close to it. After that, plot 1 figure \n",
        "   showing 3 following images:\n",
        "   -The t2 sequence, \n",
        "   -The mask \n",
        "   -The segmentation overlay on the t2 / The segmentation contour (your choice).\n",
        "    Hint: To show the overlay you may use any function learne during previous\n",
        "    exercises. As suggestion , you may choose one of these atributes on pyplot.contour \n",
        "    or modifying for the color map to plt.cm.viridis. \n",
        " \"\"\"\n",
        " \n",
        " \n",
        "t2_ima= sitk.ReadImage('/media/data/Prostate_data_sets/processed_data_set/prostatex_test_balint_cod/processed/ProstateX-0100/images/Px_ProstateX-0100_slice_7.nii')\n",
        "se_ima= sitk.ReadImage('/media/data/Prostate_data_sets/processed_data_set/prostatex_test_balint_cod/processed/ProstateX-0100/segmentations/Px_ProstateX-0100_slice_7.nii')\n",
        "\n",
        "t2_arr= sitk.GetArrayFromImage(t2_ima)\n",
        "se_arr= sitk.GetArrayFromImage(se_ima)\n",
        "\n",
        "plt.figure(),plt.subplot(1,3,1),plt.imshow(t2_arr,cmap='gray'),plt.subplot(1,3,2),\n",
        "plt.imshow(se_arr,cmap='gray'),plt.subplot(1,3,3),plt.imshow(t2_arr,cmap='gray'),\n",
        "plt.contour(se_arr,alpha=0.5)\n",
        "plt.close()\n",
        "\n",
        "plt.figure(),plt.subplot(1,3,1),plt.imshow(t2_arr,cmap='gray'),plt.subplot(1,3,2),\n",
        "plt.imshow(se_arr,cmap='gray'),plt.subplot(1,3,3),plt.imshow(t2_arr,cmap='gray'),\n",
        "plt.imshow(se_arr,cmap=plt.cm.viridis,alpha=.3)\n",
        "plt.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4e73f710502f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mt2_ima\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/data/Prostate_data_sets/processed_data_set/prostatex_test_balint_cod/processed/ProstateX-0100/images/Px_ProstateX-0100_slice_7.nii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mse_ima\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/data/Prostate_data_sets/processed_data_set/prostatex_test_balint_cod/processed/ProstateX-0100/segmentations/Px_ProstateX-0100_slice_7.nii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36mReadImage\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   8874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8875\u001b[0m     \"\"\"\n\u001b[0;32m-> 8876\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8877\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mImageViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8878\u001b[0m     \"\"\"\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Exception thrown in SimpleITK ReadImage: /tmp/SimpleITK/Code/IO/src/sitkImageReaderBase.cxx:99:\nsitk::ERROR: The file \"/media/data/Prostate_data_sets/processed_data_set/prostatex_test_balint_cod/processed/ProstateX-0100/images/Px_ProstateX-0100_slice_7.nii\" does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh2QOMdxajj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Example improving how you load your data:\n",
        "   You may have noticed that the data is structured in a specific way. This last \n",
        "was done  not only with the objective to keep the data organized, but also to \n",
        "make the data proccesing with python easier. On the following example\n",
        "you will se how to get advantage of the directory names to locate the images\n",
        "for patient 100. In this case we are going to use the python module called \n",
        "\"glob\", Run the following lines, and understand what  the code is doing.    \n",
        "\"\"\"\n",
        "# \n",
        "# First we define our patient (px) data folder\n",
        "px       = 'ProstateX-0100'\n",
        "px_fol   = '/media/data/Prostate_data_sets/processed_data_set/prostatex_test_balint_cod/processed' \n",
        "\n",
        "\n",
        "# We define to variables to save the image and segmentation path\n",
        "# as you can see that  glob list from a specific directory (px_fol) ,\n",
        "# from a specific patient (px) , all the files (*) that ends as nifti format (nii.)\n",
        "img_path = glob.glob(px_fol + '/'+px+'/images/*.nii')\n",
        "seg_path = glob.glob(px_fol + '/'+px+'/segmentations/*.nii')\n",
        "\n",
        "\"\"\"Check what contains the two variables: img_path and seg_path\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8twFhiLnarY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Write a function called create_px_path that takes a list of patients as input. Then, the function \n",
        "    should return  two lists. One list should contain the path\n",
        "    to the images and the other the paths to the segmentation files.\n",
        "    IMPORTANT: check that the odering inside the two list corresponds to the same \n",
        "    image and segmentation. For instance, if the first element in the images list  \n",
        "    corresponds to patient 100 slice 8 .Then,the first element of the segmentation \n",
        "    list should correspond to patient 100, slice 8 as well.\n",
        " \"\"\"\n",
        "def create_px_path(px_list):\n",
        "    \n",
        "    px_fol   = '/media/data/Prostate_data_sets/processed_data_set/prostatex_test_balint_cod/processed' \n",
        "    \n",
        "    x_imag = [] \n",
        "    y_segm = []\n",
        "    \n",
        "    for p in px_list:\n",
        "        images  = glob.glob(px_fol + '/'+p+'/images/*.nii')\n",
        "        segmen  = glob.glob(px_fol+ '/'+p+'/segmentations/*.nii')\n",
        "        x_imag  = x_imag+images \n",
        "        y_segm  = y_segm+segmen\n",
        "\n",
        "    return x_imag, y_segm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjZ2jwaVavDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    \n",
        "np.random.seed(180)   #Do not modify this line, it is for reproducibility.\n",
        "\"\"\"Example ,Data variability: \n",
        "     One problem regarding MR data, is the variability of intensities in the image.\n",
        "     Each patient can greatly vary from one to another.Let's have a look on this issue:\n",
        "    -Used the provided list of patients to load 6 prostate slices(zero segmentations)and plot \n",
        "     them in a 2x3 figure. \n",
        "    -Answer the following:\n",
        "        -observe the images intensities between common anatomical structures, for instance\n",
        "         the high value on the the peripheral zone, also look to the\n",
        "         dark intensities in the trainsition zone.\n",
        "      -Do you see differences between signal intensities?, \n",
        "      - Take a moment and thinkg about optimization learning algorithms,similar \n",
        "        to what you learned on registation week. Answer the following:\n",
        "       -How do you think these differences in signal intensity might affect the \n",
        "        learning process of the neural network or any other machine learning method?\n",
        "       \n",
        "       \"Your Answer:         \"  \n",
        " \"\"\"\n",
        "\n",
        "images,_ = create_px_path(os.listdir(px_fol)) \n",
        "\n",
        "#plt.figure()\n",
        "#for i in range(2):\n",
        "#   ran_int = np.random.randint(1,np.size(images))\n",
        "#   im_arra = sitk.ReadImage(images[ran_int])\n",
        "#   print(images[ran_int])\n",
        "#   im_arra = sitk.GetArrayFromImage(im_arra)\n",
        "#   plt.subplot(1,2,i+1),plt.imshow(im_arra,cmap='gray')\n",
        "# \n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_eeRGWiaziK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(180)   #Do not modify this line , it is for reproducibility.\n",
        "\"\"\"Exercise data Normalization:\n",
        "    In order to reduce the data differences , let's perform a data normalization\n",
        "    using the following formula: \n",
        "       norm_imag = image - percentile_10 / (percentile_90 - percentile_10)\n",
        "    -Therefore, define a percentile_norm function that takes an image array as\n",
        "     input and return the image data normalized using the previous formula.\n",
        "     HINT\n",
        "     Read the np.percentile function documentation to know how to obtain the 90th\n",
        "     and 10th percentile.\n",
        "     -Plot the images after being normalized and observe the differences using \n",
        "      again 2x3 figure size as the previous exercise.\n",
        "\"\"\"\n",
        "\n",
        "def percentile_norm(datas):\n",
        "    \n",
        "    x_90  = np.percentile(datas,95)\n",
        "    x_10  = np.percentile(datas,5)\n",
        "    datas -=  x_10  \n",
        "    datas  /= (x_90 - x_10)\n",
        "    \n",
        "    return datas\n",
        " \n",
        "#   \n",
        "#plt.figure()\n",
        "#for i in range(3):\n",
        "#   ran_int = np.random.randint(1,np.size(images))\n",
        "#   im_arra = sitk.ReadImage(images[ran_int])   \n",
        "#   print(images[ran_int])\n",
        "#   im_arra = sitk.GetArrayFromImage(im_arra)\n",
        "#   plt.subplot(2,3,i+1),plt.imshow(im_arra,cmap='gray')\n",
        "#   im_arra = im_arra.astype('float32')\n",
        "#   im_arra = percentile_norm(im_arra)\n",
        "#   plt.subplot(2,3,i+4),plt.imshow(im_arra,cmap='gray')   \n",
        "\n",
        " \n",
        "#plt.figure(),plt.subplot(2,2,1),plt.imshow(t2_a2,cmap='gray'),plt.subplot(2,2,2),\n",
        "#plt.imshow(t2_a2_n,cmap='gray'),plt.subplot(2,2,3),plt.imshow(t2_a,cmap='gray'),\n",
        "#plt.subplot(2,2,4),plt.imshow(t2_a_n,cmap='gray')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgCW-kqna8Lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# Splitting the data:\n",
        "  In this part of the exercise we have a function that will split our patient\n",
        "  data in training, validation and test. The function takes a list of patient\n",
        "  names adn randomy split it. First in training and test, then the training\n",
        "  is split in traning and validation. In each interation we take 20% of the patient\n",
        "  data. The function returns a data dictionary with the names of the patient\n",
        "  on each set. \n",
        "\"\"\"\n",
        "def split_data_train_val_test(px_fol):\n",
        "\n",
        "    patients = os.listdir(px_fol)\n",
        "    patients = np.asarray(patients)\n",
        "\n",
        "    ss    = ShuffleSplit(n_splits=1,test_size=0.20)\n",
        "    ss.get_n_splits(patients)\n",
        "    for train_index, test_index in ss.split(patients):\n",
        "        xt, x_test = patients[train_index], patients[test_index]\n",
        "        \n",
        "    ss = ShuffleSplit(n_splits=1, test_size=0.20)\n",
        "    ss.get_n_splits(xt)    \n",
        "    for ten_index, val_index in ss.split(xt):\n",
        "        x_train_in, x_val_in= xt[ten_index], xt[val_index]       \n",
        "   \n",
        "    px_splits = {'train': np.ndarray.tolist(x_train_in),\n",
        "                 'val'  : np.ndarray.tolist(x_val_in)  ,\n",
        "                 'test' : np.ndarray.tolist(x_test)    }\n",
        "    \n",
        "    return px_splits\n",
        "\n",
        "px_fol_path = '/media/data/Prostate_data_sets/processed_data_set/prostatex_test_balint_cod/processed'\n",
        "px_split_di = split_data_train_val_test(px_fol_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGrf3uMPa_Bt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"While training the network we will need to provide the patients data paths,\n",
        "   now that we have our data divided in sets. Use your create_px_path function from\n",
        "   exercise 2 to generate the paths of each set. You will have to provide an image\n",
        "   dictionary per set (x_train/val/test) and a segmentation dictionary(y_train /val/test).\n",
        "   We use the x and y as a convention in machine learning for training data (x) and target/label data\n",
        "   (y).\n",
        "\"\"\"\n",
        "    \n",
        "\n",
        "x_train , y_train = create_px_path(px_split_di['train'])\n",
        "x_valid , y_valid = create_px_path(px_split_di['val'])\n",
        "x_test  , y_test  = create_px_path(px_split_di['test'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpNVaWltbKzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch_norm(batch):\n",
        "    data = []\n",
        "    \n",
        "    for img in batch:\n",
        "        #print('img = '+str(img))\n",
        "        img_data = sitk.ReadImage(img) \n",
        "                \n",
        "        img_data = sitk.GetArrayFromImage(img_data)\n",
        "        img_data = img_data.astype('float32')\n",
        "        img_data = percentile_norm(img_data)\n",
        "        data.append(img_data)\n",
        "\n",
        "    data = np.stack(data)\n",
        "\n",
        "\n",
        "    data = np.reshape(data, (data.shape[0],data.shape[2],data.shape[1],1))\n",
        "    return data\n",
        " \n",
        "def generate_batch(batch):\n",
        "    data = []\n",
        "    \n",
        "    for img in batch:\n",
        "        #print('img = '+str(img))\n",
        "        img_data = sitk.ReadImage(img) \n",
        "                \n",
        "        img_data = sitk.GetArrayFromImage(img_data)\n",
        "        img_data = img_data.astype('float32')\n",
        "        data.append(img_data)\n",
        "\n",
        "    data = np.stack(data)\n",
        "\n",
        "\n",
        "    data = np.reshape(data, (data.shape[0],data.shape[2],data.shape[1],1))\n",
        "    return data   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXClT40TbOKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"DO NOT MODIFY\n",
        "   Example Data generator:\n",
        "   This function is made to generate a image batch. Neural networks consume a lot\n",
        "   of computing resources, therefore to train a network like U-net we feed it with\n",
        "   smaller portions of data, a data batch. This function takes a list of patient\n",
        "   image paths , image targets and the desired batch size. As you can see, the\n",
        "   end of the function finish with the word \"yield\" instead of return. This means \n",
        "   that the local variables will be keept while the condition of the function is\n",
        "   true, this kind of statement is used to return intermediate results. \n",
        "   In other words, we can keep \"feeding\" the Unet with data continuosly, by providing\n",
        "   data batches until we reach to the end of the image list (while \n",
        "   the function is called by the network). \n",
        "\"\"\" \n",
        "def data_generator(x_lis,y_tar,d_size):\n",
        "    while True:\n",
        "        len_lis = len(x_lis)\n",
        "        nu_part = (len_lis//d_size)+1\n",
        "        count   = 0\n",
        "        \n",
        "        for i in range(nu_part):\n",
        "        \n",
        "            if count >= len_lis:\n",
        "                continue    \n",
        "            \n",
        "            if i+1 == d_size:\n",
        "               p_list = x_lis[count:]\n",
        "               segment= y_tar[count:]\n",
        "            else:\n",
        "               p_list  = x_lis[count:count+d_size]\n",
        "               segment = y_tar[count:count+d_size]\n",
        "            \n",
        "            images = generate_batch_norm(p_list)\n",
        "            target = generate_batch(segment)\n",
        "            count += d_size \n",
        "            yield images, target  \n",
        "            \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN-WIvlFbSiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"DO NOT MODIFY\n",
        "   Do not modify\n",
        "   Dice coeficcent formula: \n",
        "   To compute the error during learning process we will use the dice \n",
        "   coefficent. Every time the network performs a prediction (y_pred= segmentation prediction),\n",
        "   this new predicted image will be compared with the ground truth (y_true). Then, \n",
        "   based on this error value, the network will update its parameters in order to improve \n",
        "   the prediction for the next time it sees an example. This process occurs mathematically\n",
        "   using differential equations. Therfore, we need define the dice function using tensors,\n",
        "   which allow us to compute the derivatives in python.\n",
        "\"\"\"\n",
        "from keras import backend as K\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    K.print_tensor(intersection, message=\"Dice intersection:\")\n",
        "    return -((2. * intersection + K.epsilon()) / (K.sum(y_true_f)\n",
        "                                                  + K.sum(y_pred_f)\n",
        "                                                  + K.epsilon()))\n",
        "    \n",
        "    \n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL2KRwilbXTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Exercise Define Unet using keras:\n",
        "   On this part you will have to complete the code to later define unet. Given\n",
        "   that the orginal unet request many computatinal resources, we will define\n",
        "   a slighly simpler unet. As you can see most of the code is written already, you\n",
        "   will need to use the image provided for this practical to complete the code.\n",
        "   what you need to do make it work is:\n",
        "   -Define the input layer accodring to your image size and color channels\n",
        "    (height, with, channels)     \n",
        "   -For the convolutional layers define the number of kernels and a kernel \n",
        "    size 3. Notice that the kernel size is doubled on each layer while the kernel\n",
        "    size is kept.\n",
        "    HINT: you may use keras documentation to help you with the code:\n",
        "       https://keras.io/layers/convolutional/\n",
        "    -Define the Max pooling layers using a pooling of 2x2\n",
        "    -When the model is finished, run the line create_unet. Should not return\n",
        "     any error message.      \n",
        "\n",
        "\"\"\"\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import MaxPooling2D, UpSampling2D, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Concatenate, Conv2D\n",
        "from keras.preprocessing.image import array_to_img\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "from keras.utils import plot_model\n",
        "    \n",
        "def create_unet():\n",
        "    '''\n",
        "    Creates a U-Net\n",
        "    '''\n",
        "    print('Creating U-Net...')\n",
        "\n",
        "    # First, we have to provide the dimensions of the input images\n",
        "    inputs = Input((192, 192,1))\n",
        "\n",
        "    conv1 = Conv2D(8, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(inputs)\n",
        "    conv1 = Conv2D(8, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    print('conv1 shape:', conv1.shape)\n",
        "    print('pool1 shape:', pool1.shape)\n",
        "\n",
        "    conv2 = Conv2D(16, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(pool1)\n",
        "    conv2 = Conv2D(16, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    print('conv2 shape:', conv2.shape)\n",
        "    print('pool2 shape:', pool2.shape)\n",
        "\n",
        "    conv3 = Conv2D(32, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(pool2)\n",
        "    conv3 = Conv2D(32, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(conv3)\n",
        "    drop4 = Dropout(0.5)(conv3)  # Added\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    print('conv3 shape:', conv3.shape)\n",
        "    print('pool3 shape:', pool3.shape)\n",
        "\n",
        "    conv4 = Conv2D(64, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(pool3)\n",
        "    conv4 = Conv2D(64, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "\n",
        "    print('conv4 shape:', conv4.shape)\n",
        "\n",
        "\n",
        "    up7 = Conv2D(32, 2, activation='relu', padding='same',\n",
        "                 kernel_initializer='he_normal')(\n",
        "                         UpSampling2D(size=(2, 2))(drop4))  # Changed\n",
        "    merge7 = Concatenate(axis=3)([conv3, up7])\n",
        "    conv7 = Conv2D(32, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(merge7)\n",
        "    conv7 = Conv2D(32, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(conv7)\n",
        "    print('conv7 shape:', conv7.shape)\n",
        "\n",
        "    up8 = Conv2D(16, 2, activation='relu', padding='same',\n",
        "                 kernel_initializer='he_normal')(\n",
        "                         UpSampling2D(size=(2, 2))(conv7))\n",
        "    merge8 = Concatenate(axis=3)([conv2, up8])\n",
        "    conv8 = Conv2D(16, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(merge8)\n",
        "    conv8 = Conv2D(16, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(conv8)\n",
        "    print('conv8 shape:', conv8.shape)\n",
        "\n",
        "    up9 = Conv2D(16, 2, activation='relu', padding='same',\n",
        "                 kernel_initializer='he_normal')(\n",
        "                         UpSampling2D(size=(2, 2))(conv8))\n",
        "    merge9 = Concatenate(axis=3)([conv1, up9])\n",
        "    conv9 = Conv2D(8, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(merge9)\n",
        "    conv9 = Conv2D(8, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation='relu', padding='same',\n",
        "                   kernel_initializer='he_normal')(conv9)\n",
        "    print('conv9 shape:', conv9.shape)\n",
        "\n",
        "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "    print('conv10 shape:', conv10.shape)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=1e-4),\n",
        "                  loss=dice_coef, metrics=[dice_coef_loss])\n",
        "\n",
        "    #model.load_weights('/home/jose/Documents/Prostate_radiomics/Unet_AIP/weights2')  # Load the pre-trained U-Net\n",
        "\n",
        "\n",
        "\n",
        "    print('Got U-Net!')\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_unet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu0G-d2Sb2a8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"Example: Training Unet\n",
        "   In this section we start training Unet. First we define a number of epochs, \n",
        "   which is  the number of times that Unet is going to \"observe\"\n",
        "   the whole training set, and learn from it the features to perform the segmentation.\n",
        "   We also define a batch size  and a history variable. In history we are going\n",
        "   to save all the training process. \n",
        "   \n",
        "   Keras package allow us to train the model using the attribute \"fit_generator\", \n",
        "   we give as input the data generator previously defined, we also define what \n",
        "   data is going to be used for training and validation.\n",
        "   \n",
        "   Run this part of the code, each epoch should take approximately 3 seconds,\n",
        "   the code will run for 300 epochs. So you can take this tame to have a short\n",
        "   coffe brake. After the training is complete, continue with the next exercise.\n",
        "\"\"\"\n",
        "filepath='/home/jose/Documents/Prostate_radiomics/Unet_AIP/weights_new/weights.{epoch:02d}_'+'.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='dice_coef_loss',period=25, verbose=1, save_best_only=True,\n",
        "                              mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "epch = 300\n",
        "batch_size = 4    \n",
        "history=model.fit_generator(data_generator(x_train,y_train, \n",
        "                            batch_size),\n",
        "            steps_per_epoch=len(x_train) // batch_size,\n",
        "            epochs=epch,\n",
        "            validation_data=data_generator(x_valid,y_valid,\n",
        "                                           batch_size),\n",
        "            validation_steps=len(x_valid) // batch_size,\n",
        "            callbacks=callbacks_list)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHLnMDnzb5CS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%m_%d_%Y_%H:%M:%S\") \n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "#plt.show()\n",
        "plt.savefig('/home/jose/Documents/Prostate_radiomics/Unet_AIPmodel_loss_'+str(date_time)+'.png')\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}